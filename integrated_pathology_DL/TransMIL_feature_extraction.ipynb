{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a747a7c1",
   "metadata": {},
   "source": [
    "# TransMIL Feature Extractor\n",
    "\n",
    "This repository provides a **TransMIL-style transformer-based feature extractor**\n",
    "for aggregating patch-level features into **slide-level (WSI-level) representations**.\n",
    "\n",
    "The implementation follows the core ideas of **TransMIL**:\n",
    "- CLS tokenâ€“based MIL aggregation\n",
    "- Transformer encoder blocks\n",
    "- PPEG (Position-aware Patch Embedding Generator) using depthwise convolutions\n",
    "\n",
    "The code is designed for **feature extraction**, not classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4062ffec-29a9-4199-beca-710c95c6b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil, sqrt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ======================================================\n",
    "# 1. Path configuration\n",
    "# ======================================================\n",
    "h5_dir = r\"\"        # Directory containing patch-level H5 files\n",
    "output_dir = r\"\"  # Output directory for slide-level CSV\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ======================================================\n",
    "# 2. Load patch-level features from H5\n",
    "# ======================================================\n",
    "def load_h5_features(h5_path):\n",
    "    \"\"\"\n",
    "    Load patch-level features from an H5 file.\n",
    "\n",
    "    Returns:\n",
    "        features (Tensor): shape (num_patches, 768)\n",
    "        coords: None (coordinates not used in this implementation)\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        features = torch.tensor(f['features'][:])\n",
    "    return features, None\n",
    "\n",
    "# ======================================================\n",
    "# 3. WSI-level Dataset\n",
    "# ======================================================\n",
    "class WSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item corresponds to one WSI (one H5 file).\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_files, h5_dir):\n",
    "        self.h5_files = h5_files\n",
    "        self.h5_dir = h5_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        h5_name = self.h5_files[idx]\n",
    "        slide_id = os.path.splitext(h5_name)[0]\n",
    "        h5_path = os.path.join(self.h5_dir, h5_name)\n",
    "        features, coords = load_h5_features(h5_path)\n",
    "        return features, coords, slide_id\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pad patch features so that WSIs with different patch counts\n",
    "    can be batched together.\n",
    "    \"\"\"\n",
    "    features = [item[0].to(device) for item in batch]\n",
    "    slide_ids = [item[2] for item in batch]\n",
    "    features_tensor = torch.nn.utils.rnn.pad_sequence(\n",
    "        features, batch_first=True\n",
    "    )\n",
    "    return features_tensor, None, slide_ids\n",
    "\n",
    "# ======================================================\n",
    "# 4. PPEG (Position-aware Patch Embedding Generator)\n",
    "# ======================================================\n",
    "class PPEG(nn.Module):\n",
    "    \"\"\"\n",
    "    Depthwise convolution-based positional encoding used in TransMIL.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=512):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
    "        self.proj1 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.proj2 = nn.Conv2d(dim, dim, 3, padding=1, groups=dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, _, C = x.shape\n",
    "        cls_token, feat_tokens = x[:, 0], x[:, 1:]\n",
    "        feat_2d = feat_tokens.transpose(1, 2).view(B, C, H, W)\n",
    "\n",
    "        feat_2d = (\n",
    "            self.proj(feat_2d)\n",
    "            + feat_2d\n",
    "            + self.proj1(feat_2d)\n",
    "            + self.proj2(feat_2d)\n",
    "        )\n",
    "\n",
    "        feat_tokens = feat_2d.flatten(2).transpose(1, 2)\n",
    "        x = torch.cat((cls_token.unsqueeze(1), feat_tokens), dim=1)\n",
    "        return x\n",
    "\n",
    "# ======================================================\n",
    "# 5. TransMIL feature extractor (no classifier)\n",
    "# ======================================================\n",
    "class TransMILFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    TransMIL backbone that outputs a slide-level CLS embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=768):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, 512))\n",
    "        self.layer1 = nn.TransformerEncoderLayer(\n",
    "            d_model=512, nhead=8, batch_first=True\n",
    "        )\n",
    "        self.pos_layer = PPEG(dim=512)\n",
    "        self.layer2 = nn.TransformerEncoderLayer(\n",
    "            d_model=512, nhead=8, batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(512)\n",
    "\n",
    "    def forward(self, x, coords=None):\n",
    "        B, N, _ = x.shape\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        # Pad tokens to form a square grid for PPEG\n",
    "        H = W = int(ceil(sqrt(N)))\n",
    "        pad_len = H * W - N\n",
    "        if pad_len > 0:\n",
    "            x = torch.cat([x, x[:, :pad_len, :]], dim=1)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, 1, -1).to(x.device)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.pos_layer(x, H, W)\n",
    "        x = self.layer2(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x[:, 0]  # CLS token as slide-level feature\n",
    "\n",
    "# ======================================================\n",
    "# 6. Run feature extraction\n",
    "# ======================================================\n",
    "h5_files = [f for f in os.listdir(h5_dir) if f.endswith(\".h5\")]\n",
    "dataset = WSIDataset(h5_files, h5_dir)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = TransMILFeatureExtractor(input_dim=768).to(device)\n",
    "model.eval()\n",
    "\n",
    "all_features = []\n",
    "slide_names = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, _, slide_ids in loader:\n",
    "        features = features.to(device)\n",
    "        slide_feat = model(features)\n",
    "        all_features.extend(slide_feat.cpu().numpy())\n",
    "        slide_names.extend(slide_ids)\n",
    "\n",
    "# ======================================================\n",
    "# 7. Save CSV\n",
    "# ======================================================\n",
    "df = pd.DataFrame(all_features)\n",
    "df.columns = [f\"DL_{i+1}\" for i in range(df.shape[1])]\n",
    "df.insert(0, \"Slide_ID\", slide_names)\n",
    "\n",
    "csv_path = os.path.join(output_dir, \"TransMIL.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved slide-level features to {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
